# Little's RAW

[guide](https://www.dell.com/community/zh/conversations/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E5%92%8C%E4%BF%9D%E6%8A%A4-%E8%B5%84%E6%96%99%E6%96%87%E6%A1%A3/%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97little-law-utilization-law/647f3701f4ccf8a8dedc796f)

https://blog.betacat.io/post/2023/05/explain-latency-and-utilization-using-queueing-theory/

IOPS与i/o size、random/sequential、read/write ratio、App threading-model、response time baseline等诸多因素相关，这些因素组合起来便可以描述一种类型的I/O，我们称之为【I/O profile】。不同的因素组合得到的IOPS都不一样，通常我们看到的【标称IOPS】都是在某一个固定组合下测得的，拿到你自己的生产环境中，未必能达到标称值。这也是为什么要做前期的performance analysis/sizing的缘故。

bandwidth = Frequency * bit-width


Real-world result = nominal * 70% -> 我所标称的数据都是*70%（性能计算：Little Law & Utilization Law）以尽可能接近实际数据，但如果另外提供了由资料获得的更为准确的数据，则以其为准。
Bandwidth = frequency * bit-width

     QPI带宽：假设QPI频率==2.8 Ghz

     × 2 bits/Hz (double data rate)

     × 20 (QPI link width)

     × (64/80) (data bits/flit bits)

     × 2 (unidirectional send and receive operating simultaneously)

     ÷ 8 (bits/byte)

     = 22.4 GB/s


Little’s Law 是排队论中的一个基本定理，这里的 Little 完全是字面意思，取自于作者 John D.C. Little ，跟逻辑意义上的大小无关。它用于描述一个处于稳定状态下的排队系统中请求数、到达率以及平均逗留时间之间的关系：

L=λW

其中：

    L：系统中的平均请求数（同时包括正在接受服务的请求和等待服务的请求）。
    λ：单位时间内到达系统的请求数量，即到达率。
    W：请求在系统中的平均逗留时间（包括逗留时间和服务时间），即我们感知到的延迟。

而稳定状态是指，从长期来看，到达率和服务率之间达到了动态平衡，否则就会出现队列无限增长或者长期排空的现象。从这个前提条件也可以看出，Little's Law是一个基于统计平均值的定理，它可能无法反映某些特定个体、或者特定时间点的情况。

l  确保磁盘稳定运行所允许的最大请求数量 L

l  I/O请求达到速率 λ

l  磁盘处理每一个I/O所花费的时间 W


     因此，保证一块磁盘稳定运行所允许的最大I/O请求数量 L = I/O请求达到速率λ * 磁盘处理每一个I/O所花费的时间W，即L = λW；同理，对于一个I/O控制器，到达速率必须 < 服务速率，或者说服务时间必须 < 内部到达时间，否则I/O控制器的处理能力无法满足过量的I/O请求，必然会导致性能下降。


          结合Utilization Law（不介绍了，直接应用，它可用于描述I/O控制器的利用率），公式为 U = λ * Rs


l  U = I/O控制器的利用率

l  Rs = 服务时间，即控制器处理一个I/O的平均时间，对于磁盘来说，服务时间 Rs = 寻道时间 + 旋转延迟 + 内部传输速率（数据从一个盘面上的单个磁道传输到Buffer的速率），所以通常是一个定值，由磁盘本身的物理特性决定。

l  λ = 到达速率


Little Law + Utilization Law可以推导出如下公式（推导过程省略，直接用）


l  平均响应时间 R = Rs / (1-U)

l  平均队列长度 Nq = U^2 /(1-U)


     有了如上这些公式，我们来考虑这样一个磁盘系统， λ = 100个/秒，Rs = 8ms，我们可以得到


l  磁盘利用率 U = Rs / Ra = 8/10 = 0.8或80%

l  响应时间R = Rs / (1-U) = 8/(1-0.8) = 40ms

l  平均队列长度Nq = U^2 / (1-U) = 0.8^2 / (1-0.8) = 3.2

l  一个请求在队列中的等待时间 = 【U * Rs】或【响应时间 – 服务时间】 = 40 – 8 = 32ms


     若把控制器处理能力加倍，则服务时间和利用率都会减半，Rs = 4ms，U = 40%。此时，响应时间R可以大大降低；同理，如果处理能力减半，那么服务时间和利用率都会极大增加。这里有一个非常重要的概念，就是我们经常提到的，随着利用率增加到某一个点，如果继续上升，那么响应时间会呈指数形式增长，也就是说R和U并不是线性的关系，我们分析一下【响应时间R = Rs / (1-U)】来看看是为什么：


     平均响应时间 R = Rs / (1-U)，Rs是定值，可见，当U = 1时，也就是控制器饱和时，【响应时间R】趋近于无穷大，这是一个极限的概念，2013-7-24 16-44-53.jpg ，当U趋向于1时，又Rs是常量，所以R趋向于无穷大。因此，处于100%利用率的控制器就是瓶颈所在，它会迫使I/O序列化（I/O serialization），即每个I/O都必须在队列中等待它前面的I/O被处理完毕之后才能得到服务。一旦队列无限加大（一般buffer会有控制机制阻止队列的无限增长，比如Fiber Channel BB Credit，TCP Window，Ethernet PAUSE等等），响应时间会急剧上升。


     通常我们都认为当利用率达到70%以后，未来的继续增长会使得性能以指数形式下降，而不是线性的。为什么是非线性的，大家可以尝试画一下 R= Rs/ (1-U) 的函数图像，在U逐渐趋向于1时，R趋向于无穷大，垂直渐近线是 x = 1。不过我不明白70%是如何计算出来的，可能是求U在 [0,1)范围内的导数通过比较斜率变化率来判断的？事实上，当U取0.9，0.99，0.999,....,0.9999999时，你会发现R = 10Rs, 100Rs, 1000Rs,....,10000000Rs，R以指数形式增长。而U取0.1，0.11，0.111时，R的增加就缓慢很多。随着U的取值增加，R的上升趋势也会以非线性的方式呈上升趋势。70%可能是通过数学方式计算得到，也可能只是一个比较得来的经验值，擅长数学的朋友可以补充说明一下。